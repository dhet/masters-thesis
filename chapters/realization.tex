
\chapter{Approach}\label{chapter:realization}

In this chapter, the main approach of this thesis is presented. The chapter starts with an abstract description of the approach with the aim of providing a high-level overview of the underlying concepts (\autoref{sec:concept}). Then, a list of requirements and desirable quality attributes is given (\autoref{sec:requirements}) on the basis of which the approach is later evaluated (\autoref{chapter:discussion}). The section that follows gives a concrete example of how the system may be realized. For this, an exemplary technology stack is presented, whereby each of the employed technologies is discussed in detail (\autoref{sec:realization}). This part builds the basis for the subsequent chapter, where a system based on the presented technologies is evaluated.

%
%
%
%
%
%
%
%
%
%

\section{Concept} \label{sec:concept}
The objective of this thesis is to find a way to handle increased computational demand in mobile cyber-physical systems, and in particular automotive systems. For this, an approach is presented that allows single vehicular functions to be offloaded to the cloud.
Since connectivity in such systems is often unstable, the offloading must be accomplished in an instantaneous and smooth fashion. At the same time, operation may not be interrupted and the cohesion of the system must be preserved at all times. The key concept to facilitate this is replication. 

At the core of the approach is the idea to split functionality into isolated units which may be deployed redundantly on both, the vehicle's on-board system, and on high-performance machines in remote data centers. For this, the system needs to facilitate the clean separation of logic according to responsibilities. The service-oriented architectural paradigm is a suitable way to achieve this\todo{rephrase}. Service-orientated architectures aim to divide functionality into isolated modules, so-called \emph{services}. Each service provides an offering to other services by means of a clearly defined, machine-readable interface. Such offering may be the provisioning of some sort of data, or functionality (algorithms and business logic). All services of the system are working together in synergy to achieve a common goal, \ie , the continuous operation of a vehicle. 

\todo[inline]{
A challenge in such a system 

For this, services must be able to communicate anonymously. A communication paradigm that fulfills this requirement is the publish-subscribe paradigm.
Services expose their functionality by means of topics in a publish-subscribe environment. 

Switch must be feasible at run-time

transition must be fluent

Communication shall be ubiquitous

A major problem in automotive architectures is the management of data. As a result of the historically grown nature, whereby each ECU is highly specialized in a very narrow range of duties, there is no consistent model of data---each ECU has its own view on data which may very well differ from other ECU's view \cite{broy2006challenges}. It is evident that data need to be put into the center of attention. Data-centricity is a communication style that follows this goal. provides common, consistent view on data. global shared data space.
}

The method of exposition is data-centric: instead of providing \emph{methods} that other services may invoke (RPC style), services offer \emph{data}. Any service interested in receiving a certain kind of data listens in on a topic on which such data is published. This approach greatly helps to decouple the system as services do not need to have references to one another. As a result, services may evolve without having to deal with interface interdependencies.

\todo[inline]{introduce term "service instance"}

A major goal of the approach is scalability, and in particular, horizontal scalability. Therefore, replication is key. The service-oriented approach alleviates this tremendously, provided that certain design principles are applied. Hence, throughout the design and implementation of the envisioned system, several design goals need to be kept in mind. Firstly, services ought to be \textbf{stateless}. Statelessness facilitates replication as sharing state among many instances proves to be difficult. Consistency is hard to achieve and locking mechanisms may become a bottleneck.\todo{more on consistency models this in tanenbaum...} Furthermore, services should be \textbf{fine-grained}. A high-resolution granularity allows for detailed control over which services should be replicated. That way, computational bottlenecks can be more easily singled-out and eliminated. An added benefit is increased extensibility and faster software updates. However, trade-offs need to be considered. If services are too fine-grained, they need to communicate more, and as a result, the communication channel might become a bottleneck. Furthermore, too many services unnecessarily increase complexity.

Another design goal to keep in mind is \textbf{isolation}. Services should have limited knowledge of both, location and topology. The aim should be to hide anything that isn't directly related to the reception of data. Through that, loose coupling is achieved. One aspect of isolation is self-containment. Services should be kept together with all their dependencies as a single unit that may be deployed on any hardware platform. By packaging services in self-contained environments, they may be moved between different computing nodes. This property is the most important one to achieve cloud scalability. Commonly used tools to facilitate this are virtualization and containerization.

The last question that remains is how services are connected. Since services may be duplicated and migrated between computing nodes, special emphasis needs to be put on location/relocation transparency and dynamic topology management. In the approach, the use of virtual overlay networks is suggested for this purpose. Especially challenging is the fact that the overlay must work on top of a substrate network made up of numerous globally dispersed nodes, of which some continuously change their location. As a result, the substrate network is exceptionally unreliable.

\paragraph{}

\begin{figure}[htpb]
  \centering
  \includegraphics[width=0.8\textwidth]{figures/idea.pdf}
  \caption[Conceptual sketch of the approach]{Conceptual sketch of the approach, demonstrating location transparent replication of services in the cloud}\label{fig:idea} \todo[inline]{add cloud exclusive service?}
\end{figure}

\autoref{fig:idea} presents a schematic view of the approach. The box on the left-hand side represents a vehicle. In the vehicle, several interconnected services are deployed. What is not depicted, but naturally given, is that these services run on distributed embedded devices spread over the vehicle's E/E system. On the right-hand side, the cloud is depicted, which, in actuality, is a collection of high-performance computing nodes. Vehicle and cloud are physically separated and connected via some sort of network, which is accessible, \eg , by means of 5G. As can be observed in the figure, some of the vehicle-intrinsic services are replicated in the cloud (\ding{117}, \ding{115}). Examples of such services could be functions for predicting trajectories, gaze detection, or machine learning algorithms. The duplication and varying size of the service boxes depicted in the image is indicative of horizontal and vertical scaling, respectively. It doesn't always make sense to replicate services in the cloud, \eg , because they are computationally inexpensive, or because they require access to sensors and actors which can only be found in the vehicle (\ding{70}, \ding{108}, \ding{58}). Those services have their firm place within the vehicle and are referred to as \emph{fixed} services. Their counterpart, \ie , services that may run ubiquitously, are called \emph{volatile} services. The discrepancy between fixed and volatile services emphasizes the need to split functionality into fine-grained services so that computational bottlenecks can be isolated and then eliminated. A good advice is to extract services connected to sensors and actors in minimal services ("\emph{access services}") that do nothing but provide a low-level interface to sensor data.

\paragraph{Key Challenges}

In this section, a theoretical approach was presented to offload computations to the cloud. To achieve this, the approach suggests to split functionality into fine-grained services that may be replicated and migrated smoothly between vehicle and cloud. The problem at hand can be categorized in three key challenges which need to be addressed:

\begin{enumerate}[(i)]
\item \textbf{Reliable information exchange}: Services must be able to communicate in a reliable manner, without needing direct references to one another.
\item \textbf{Isolation}: Services need to be packed in self-contained execution environments with all their dependencies.
\item \textbf{Connectivity}: Services need to be able to autonomously create connections between each other and stay connected, regardless of where they are.
\end{enumerate}

%
%
%
%
%
%
%
%
%
%

\section{Requirements and Quality Attributes} \label{sec:requirements}
The previous section already touched on desirable quality attributes to keep in mind when implementing the approach. Still, a rigor requirement analysis is needed in order to be able to thoroughly evaluate it. To this end, a detailed requirement list is presented which an implementation of the envisioned system should aim to fulfill. The list is loosely based on the work of \citeauthor*{o2007quality} \cite{o2007quality}.

\todo[inline]{More info: Dependable systems [Kopetz, Verissimo]: Availability, Reliability, Safety, Maintainability}

\paragraph{Availability.}
Availability states how likely it is that, at any given point in time, a system is ready to be used by its users \cite{tanenbaum2017distributed}. The period in which a system or service is unavailable is called \emph{downtime}. Sources of downtime can be, \eg , maintenance work, temporary congestion, or any kind of failure. A design goal when building and running software systems is to minimize downtime, and thereby maximize availability. This goal is not trivial to achieve as many sources of decreased availability are hard to predict, \eg\ in case of hardware failures. A key technique for handling downtime is redundancy, whereby critical systems, or those susceptible to downtime, have a replacement ready to be used at all times. A prerequisite for redundancy to take effect is that the system features quick failure detection and smooth transition mechanisms so that it can quickly reroute requests to the redundant service.

\paragraph{Reliability.}
Reliability states how long a system can continuously run without failure. A reliable system is available for prolonged periods of time without interruption. Although reliability is related to availability, there is a clear distinction between the two. While reliability states a continuous period of operability, availability concerns operability at a given point in time. For example, a system that works fine most of the time but becomes unavailable for a few milliseconds every hour is highly available, but not reliable. Hence, a highly reliable system is not necessarily a highly available one and vice versa \cite{tanenbaum2017distributed}.

In real-time systems, even a temporary failure could have disastrous effects. If the system is a hard real-time system, a single missed deadline is even equivalent to a complete system failure. Ensuring reliability is therefore of utmost importance. As with availability, a way to mitigate the effects of poor reliability is redundancy.

Special precautions need to be taken for \emph{distributed} systems as their communication channels are inherently unreliable \cite{tanenbaum2017distributed}. In practice, this means that the messaging system needs to provide guarantees for a timely and robust message delivery. In addition, certain assurances must be given, \eg , that messages are delivered in order or that every message is delivered only once \cite{o2007quality}. 

\paragraph{Safety.}
The safety of system states how resilient \wrt\ failures it is, and in case a failure occurs, how well it can handle it. A safe system manages to protect the health and wellbeing of humans involved in the operation of the system and its surrounding bystanders.
As human lives are at stake in road traffic environments, vehicles are a prime example of systems that need to be safe.

Critical functions need to operate in a fail-operational fashion, \ie , in case they fail, the situation needs to be handled gracefully, without putting the passengers in danger. To this end, special precautions need to be taken throughout the whole process of development, provisioning, operation, and service of functions. ISO 26262 \cite{iso201126262} provides the standards that vehicular E/E systems need to adhere to in order to fulfill the necessary safety requirements. Different parts of the system need to be compliant to different classes of safety, indicated by automotive safety integrity levels (ASILs).

\paragraph{Interoperability.} 
In systems composed of a number of heterogeneous components that interact with each other, there needs to be a common set of rules and semantics that all involved parties must comply with. If such rules exist, so that diverse components may interact with each other, they are said to be interoperable.
A major barrier to interoperability is vendor lock-in, or more general, platform lock-in. Lock-in describes a situation in which a technology is rooted so deep within the system that it can barely be removed without considerable effort. Lock-in is detrimental to system design as it creates dependencies, and thus, enforces tight coupling. Especially in the automotive domain, in which many parts of the system are developed by a vast number of independent teams and suppliers \cite{broy2006challenges}, interoperability needs to be kept in mind. A way to achieve a high degree of interoperability is to avoid proprietary, closed-source solutions and to favor open standards instead.


\paragraph{Security.}
In road traffic, flaws in a system's IT security have direct implications for safety. Since safety is of utmost importance the same is true for security. 

Several developments call for an increased emphasis on security.

Increasing amounts of code in vehicles -> increased attack surface

increased connectivity -> exposed to the public 

autonomous driving: software-controlled actuator systems. -> malicious attackers might remote control vehicle


Precautions:

Proper isolation of software components is needed.

state-of-the-art encryption and security measures are needed to ensure the integrity, authenticity, and confidentiality of the system.

Data in the cloud needs to be stored safely.


\paragraph{Performance.}
Services in an automotive SOA are deployed on embedded computing devices that must fulfill real-time requirements. This is in stark contrast to services in traditional SOAs that often run on high performance machines. The resource constrained nature of embedded systems requires special operating systems, communication technologies and programming techniques.

low response times, high throughput and timeliness (Real-time requirements must be fulfilled)

performance is influenced by scalability: scalability can help to increase performance

Measures:

Low network overhead must be given

support for compiled programming languages must be given

no unnecessary overhead may be incurred


\paragraph{Extensibility.} 


It must be easily feasible to extend an SOA with new services and to update existing ones. The provisioning of new functionality must be possible not only at design-time but also at run-time. Modern automotive software architectures must deal with the fact that vehicular functions may be modified, added, or unlocked at run-time through automatic software updates.

\paragraph{Adaptability.}
Services deployed in a moving vehicle are exposed to a rapidly changing environment. Systems may unexpectedly fail, e. g. due to external forces. Automotive E/E architectures must be able to quickly react to such circumstances. Furthermore, services should be portable to facilitate repartitioning. For this reason they must adapt to run on different hardware platforms.

\paragraph{Testability.}
There are many ways in which a distributed system may break. Since operational safety is of paramount importance in automotive, testability is a key requirement. Components of an SOA must be testable in isolation as well as in interplay with other components. For this purpose, modern software development employs continuous integration tools that help to continually validate the correctness of a system throughout the whole development cycle. Automotive E/E architectures need to be adapted to make it feasible to employ such development practices.


\paragraph{Scalability.}
Scalability \todo{too basic, move to a previous chapter} is a system's ability to handle increased computational demand by means of expansion. Generally, a distinction between two types of scalability is made: horizontal scalability, by which workload is distributed across an increased number of nodes (scaling out), and vertical scalability, by which a single node is upgraded with more powerful hardware (scaling up) \cite{tanenbaum2017distributed}. While vertical scalability is easier to realize, horizontal scalability scales much farther \todo{rephrase}. This is, because at a certain point, it becomes cheaper to add entire nodes, than to further upgrade a node with increasingly expensive hardware.

A technique to achieve horizontal scalability is to replicate individual components and to deploy them on physically separated hosts to bypass computational and networking bottlenecks. Under certain circumstances it might be advisable to deploy such replications, or even the whole system, in the cloud, in order to offload computations. Cloud infrastructures often have means to dynamically scale out in an elastic fashion, depending on demand. This has the added benefit that also administration effort is offloaded, which may reduce operational expenses \cite{vaquero2011dynamically}.

Similarly, the messaging system must allow for the easy addition of components without negatively affecting performance.

%
%
%
%
%
%
%
%
%
%

\section{Realization} \label{sec:realization}
After having discussed the basic concept of the approach in \autoref{sec:concept}, in this section, an exemplary realization is presented. Previously, three key challenges were identified:
\begin{inparaenum}[(i)]
  \item \emph{reliable information exchange},
  \item \emph{isolation}, and
  \item \emph{connectivity}. 
\end{inparaenum}
To tackle these challenges, three technologies are proposed:

\begin{enumerate}[(i)]
\item \textbf{DDS} to enable \emph{reliable information exchange},
\item \textbf{\docker} as containerization tool to achieve \emph{isolation} and portability of services, and
\item \textbf{\wnet} as means to provide \emph{connectivity} between the containerized services.
\end{enumerate}

In the following, these technologies are described in detail. With the aid of the requirements given in \autoref{sec:requirements} it is explained why these technologies are are a suitable implementation of the \todo{weird sentence} approach. 


\subsection{DDS as Messaging Middleware}

DDS is a promising candidate for a middleware that fulfills requirements to a satisfying degree.

OpenDDS was used.

Why DDS?

\paragraph{Dynamic Service Discovery.}

\paragraph{Data Centricity.}

\paragraph{Asynchronous Messaging.}

\paragraph{Location Transparency.}

\paragraph{Decentralization.}

\paragraph{Platform Independence.}


\subsubsection{Failover Mechanism}

DDS has ways to ensure reliable communication, even over unreliable transmission channels. For example, it allows for the realization of a failover mechanism which allows a failed service to be replaced by a backup service in a smooth and performant fashion. 

When DDS "observes" that a given service is unresponsive it automatically instructs another service to take over, provided that one exists. This mechanism is realized via the QoS policies \ownership , \ostrength\ and \liveliness\ . 

By assigning a topic the \ownership\ value "\qos{exclusive}" one can specify that only a single data writer may write to that topic at any given time. Which data writer is given that prerogative is determined by the data writer's \ostrength\ value. The data writer that possesses the higher value is eligible to write to the topic.

\liveliness\ is used to determine whether a data writer or data reader is "alive", \ie , responsive. For data writers, it is sufficient that it writes within a specified time interval in order to be considered "alive". For data readers, on the other hand, there are several ways in which it can signal liveliness. One way is to send continuous "heartbeat" messages.

\ownership\ can be combined with \liveliness\ to realize a failover mechanism.
\todo[inline]{how exactly?}


\subsubsection{DDS for Automotive Systems}
Automotive software systems have previously relied -- and, to some degree, will continue to do so -- on low-level, low-bandwidth transport protocols such as CAN, LIN, etc. For the longest time, networks stacks based on those protocols were sufficient to meet the basic requirements of delivering vehicular sensor data and x-by-wire functions. However, driven by the emergence of innovative functions, the demands for vehicle intrinsic networks are skyrocketing. In particular, more and more sensor data from increasingly bandwidth-hungry sensors, such as cameras and LIDARs is feeding into advanced systems such as ADAS. At the same time, these functions require computational capabilities that go way beyond of what is possible with the microcontrollers typically used in traditional ECUs. High-performance computer systems based on high-level operating systems, supported by bandwidth-friendly networking protocols are needed to meet the new requirements. A new generation of low-level network protocols found their way into the vehicle. Notable mentions are FlexRay, and TSN. A question that remains is whether DDS is a suitable choice for the use within vehicles, and whether DDS may be used efficiently on top of these lower level protocols. \citeauthor*{bouhouch2013dds} have shown \cite{bouhouch2013dds} that DDS is indeed a suitable middleware to be used in vehicular networks.


DDS is designed for resource constrained real-time applications such as sensor networks or industrial automation.

DDS allows to configure how much of a system's resources an DDS-enabled application may use. Consequently, it is the middleware's responsibility to allocate resources as needed while still staying within the specified boundaries. At the same time, priorities aligning with the application's QoS settings need to be considered. DDS takes this burden off the programmer's shoulders.



\subsubsection{Separation of User Data}
\todo[inline]{nur eine idee}
The presented approach relies on a single cloud infrastructure, while at the same time, a vast number of customers need to be served. This poses a challenge concerning the separation of data. Confidentiality and privacy of user-specific application data must be preserved. Similarly, the result of a computation commissioned by a specific vehicle must be returned to exactly that vehicle, and no one else. 

Gladly, DDS offers a solution to this. In DDS, topics are not restricted to a single domain, \ie , they may be reused in multiple domains. If, \eg , a publisher belongs to \texttt{Domain $\alpha$} and publishes data on \texttt{Topic A}. Then, a data reader that reads from \texttt{Topic A} but belongs to \texttt{Domain $\beta$} may not read the data. Therefore, through domains, the same application may be reused several times, while keeping topic data separate. This principle is take advantage of in the presented approach: Domains are used to separate user data, such that for each user there is one user-specific domain.




\subsection{\docker\ as Containerization Technology}

\paragraph{Portability} Containers need to run in vehicles and cloud -> \docker is available on many platforms, ARM version is fully functional

Besides providing isolation, \docker\ has a number of other benefits. 
\paragraph{Innovation Pressure}(not docker specific) calls for fast development cycles -> CI/CD.

\paragraph{Light-weight}: Important for embedded systems, provides: fast spin-up, low overhead

\paragraph{Flexible network interfaces}: provide connection between distributed containers

\paragraph{layered images}: save disk space


\subsubsection{Multi Platform Compatibility} 
The primary purpose of containerization is to build portable execution environments that may run on a broad range of computing systems. Generally speaking, portability of containers is restricted to software compatibility, \ie , containers may run on a variety of different operating systems. However, since containerized applications run directly on the kernel of the host system -- and do not employ virtualization---they are not portable between different hardware architectures. \Ie , applications packed in containers are not binary compatible. For instance, given an application that was built to run on a x86-based processor and packaged in a container. The same container will not run on a different processor, \eg\ one which is ARM-based. This poses a challenge for the approach at hand. Embedded systems are often based on particular hardware architectures which are tailored towards operation in resource constrained environments. Computing nodes in a data centers, on the other hand, are typically based on architectures aimed at providing a maximum level of performance, such as x86. Given that the envisioned scenario exactly matches this use case, this problem is of particular interested for this thesis.

Several approaches exist to tackle this problem. QEMU... This approach turned out to be unsuitable for the intended use case as multicast is not well supported by QEMU.


\subsubsection{Containerized Services}
One of \docker 's salient features is its layered approach to images.

\begin{figure}[htpb]
  \centering
  \includegraphics[width=\textwidth]{figures/docker-sharing}
  \caption[An example of containerized services]{An example of four containerized service instances, some sharing common logic to save disk space and facilitate fast updates}\label{fig:service-containers} 
\end{figure}

\autoref{fig:service-containers} shows an example of three containerized services running on two different machines, \experim{Host I} and \experim{Host II}. The former hosts two instances of \experim{Service A}, and one instance of \experim{Service B}. On the second host only one service instance is running, namely one of type \experim{Service C}. All services are packaged in their own, separate container. The containers are made up of three stacked images---the bottom two are common to all services. The bottommost image ("\emph{base image}") contains the file system layers of a minimal operating system. In the example  \emph{Debian}\footnote{\url{www.debian.org}} was used. The base image only contains a limited selection of Linux tools, such as \texttt{ls}, \texttt{cat}, etc. The purpose of a base image is to lay a good foundation that enables users to work comfortably within the container. In the case of Debian, the \emph{aptitude} package manager is additionally included which enables users to easily install further \todo{QEMU?} tools. 

Next, an \emph{intermediate image} is built on top of the base image. The intermediate image adds further layers containing the \emph{run-time environment}, and in particular, the shared libraries of OpenDDS. At this stage, the container is able to run any DDS application that was built utilizing OpenDDS. The intermediate image could theoretically contain more libraries and tools that are common to all services. In this case, however, DDS was sufficient\todo{updaten, falls es zu case study kommt} . The bottom two layers are common to all services, and thanks to \docker 's layered images, can be shared... \todo{besser erklaeren}

At the top, finally, sit the \emph{service images}. In these images the actual service logic is contained, and more precisely, the service's binary and configuration files. The service images are unique to each service, and are not shared, except when the same service is instantiated multiple times on the same machine (\experim{Service A}).


\input{chapters/sections/weave}








