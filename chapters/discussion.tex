\chapter{Discussion}\label{chapter:discussion}
In \autoref{chapter:realization}, the thesis' main approach was introduced. As part of this, an exemplary technology stack to realize the system was proposed. The exemplary solution, which is based on DDS, \docker , and \wnet , was then assessed with the aid of a number of benchmarks (\cf \autoref{chapter:evaluation}). In this chapter, the proposed solution is discussed, and its merits as well as its flaws are pointed out. The list of requirements given in \autoref{sec:requirements} and the benchmark results from the previous chapter serve as the foundation of the discussion. 


\section{Requirement Analysis}
\todo[inline]{bring list in correct order}
\paragraph{Scalability.}
The approach is strongly focused on scalability. 

With DDS, it is easy to scale out services
\begin{itemize}
\item anonymous multicast communication facilitates scalability. new services don't need to explicitly register to related services. All communication goes to a multicast address. The underlying infrastructure takes care that messages are distributed accordingly.
\item automatic service discovery: it's easy to add new services. It's enough to start the program and the publisher/subscriber can automatically participate in a topic.
\item Decentralization also improves scalability: In centralized systems, there is often a single point of failure which may be overloaded with increasing demand. 
\item However, performance properties when adding publishers or subscribers was not tested. Previous work?
\end{itemize}

With \docker\ it is easy to replicate services. 
\begin{itemize}
\item \docker\ can be controlled via mature RESTful API which makes it easy to launch containers in a unified manner
\item Container spin-up is extraordinarily fast. Helps elasticity.
\end{itemize}

Adding containers to a Weave overlay happens implicitly when the host is already running a weave router. Starting the weave router on a machine can be done at system start up via shell script. Gripe: It is not known if \weave 's performance degrades with many nodes in the overlay. This is future work.

(Weave nodes can be easily integrated into existing networks. When the Weave router is already in place on a host, merely starting a container is enough to connect it to the overlay.)

\paragraph{Availability / Reliability.}
Moving vehicles are are very likely to lose reception during operation, \eg , when navigating through remote areas. At the center of the presented approach is cloud connectivity, and hence, the reliability of the network is a major concern. Thus, a primary objective when designing the system was to make it as resilient to connection losses as possible. A prerequisite for handling reliability issues is fast failure detection and a quick fail-over mechanism so that timing requirements can be met and downtime is kept at a minimum. With its support for redundancy and failure detection, DDS is perfectly equipped for such cases. DDS' way of guaranteeing reliable information exchange is achieved by QoS policies. For failure detection, DDS employs a liveliness mechanism whereby services are either proactively, or reactively, probed for responsiveness. If a service fails to meet the demand, it is declared "dead". In such cases, fallback services may be elected as (temporary) replacement. As soon as the original service's operability restored, it may take over again.

While \wnet\ doesn't quite reach the level of replication- and failure transparency provided by DDS, it has other ways to deal with unreliable underlay networks. When a link between two nodes is interrupted \weave\ takes no proactive measures to find an alternative link but it reconnects as soon as connectivity is restored. Thus, a moderate resilience to connection loss is discernible.

\paragraph{Security.}
Security was a major concern when designing the approach. In fact, \weave 's security features were one of the primary reasons why it was chosen as overlay networking technology. In particular, its support for end-to-end encryption ensures the confidentiality and integrity of the communication channel, even in insecure networks such as the Internet. \wnet 's security is based on IPSec and state-of-the-art encryption algorithms. However, questions remain about the usability of \weave 's encryption mechanism. \weave\ employs a shared secret approach, \ie , a password needs to be present on all participating hosts. How this secret is to be securely stored and how situations of leakage are dealt with are an open question yet to be answered.

Aside from encryption, isolation is an important means to improve the security of a system. By integrating isolation measures, security perimeters can be created which are difficult to penetrate. The more layers of isolation there are the better the system can be protected from attackers. The approach leverages \docker\ to provide isolation. Each service instance is running within the perimeters of a container. However, whether \docker 's isolation properties are sufficient in terms of security is debatable. The fact of the matter is, however, that any degree of isolation is better than no isolation. Hence, for now, the security of \docker\ is considered sufficient, although a rigor security analysis is still to be done.
\todo[inline]{
The most important method to keep a system secure is to allow for fast and reliable updates. \docker\ promises exactly that.

The security requirement is partly fulfilled.
}
\paragraph{Performance.}
One of the main motivations behind the approach is to support the resource-constrained on-board computing system of vehicles by offloading computations to the cloud, and thereby improve the performance of the whole system. In \autoref{chapter:evaluation} it was shown that the approach manages to fulfill the performance requirement to a satisfying degree. This is because all technologies were chosen, in part, on the basis of their performance properties\todo{widerspruch zu unten?} .

DDS exhibits great performance characteristics because it is, from the ground up, designed to perform well. The fact that DDS employs multithreading-based asynchronous programming, and that virtually all DDS implementations are implemented in C++, underline this statement. In section \ref{sec:ddslatency} DDS was evaluated regarding its latency characteristics in an overlay setting. The results of the benchmark show that DDS incurs reasonable protocol overhead. In that benchmark, DDS was compared to ICMP---a protocol which is not designed for information exchange. The comparison is therefore imbalanced to the detriment of DDS. The fact that DDS still performed comparatively well is a strong argument for its aptitude. 

Similar to DDS, \docker\ was built with performance in mind. Many benchmarks have been conducted with the aim to challenge this statement \cite{felter2015updated,morabito2015hypervisors}. They all agree that \docker\ incurs minimal computational and IO overhead, provided that it is configured properly\todo{mehr info? Mehr referenzen!} .

A slightly less optimistic picture paint the benchmark results for the evaluation of \wnet . The results reveal that the overlay technology adds a barely noticeable latency overhead, even when applying encryption (\cf section \ref{sec:plainlatency}). Likewise, network throughput takes only a minor hit (\cf section \ref{sec:throughput}). However, these properties only apply when enough computing resources are present. In cases where computing power is insufficient, severe network performance degradations may be the result. The reason for this is that overlay networking, \ie\ the wrapping and unwrapping of encapsulated data, puts significant load on the CPU. In section \ref{sec:utilization}, a case was explored in which the test nodes reached their computational limit such that the CPU became the bottleneck. As a result, only a fraction of the theoretically achievable network bandwidth could be utilized. Expressed in figures, the effective throughput stalled at around 23 Mbit/s. The severe computational overhead can be explained by \weave 's custom encapsulation protocol ("sleeve"), which is automatically used for overlays that span over the Internet. In this mode, packets need to traverse the \weave\ router. Because the router is a user space process, many context switches need to be performed during continuous data transmissions. This circumstance causes significant delays if many packets need to be sent in rapid succession. Considering that it is a goal of the approach to minimize energy consumption, it can be concluded that \wnet\ is definitely not the best suited technology for the use case at hand\todo{satz meh.} .

\paragraph{Extensibility.}
The extensibility of the approach is to a large extent facilitated by DDS. In the DCPS paradigm, data is provided "as is", \ie , there are no implications or restrictions \wrt\ how that data is used. A newly added service is not concerned with the original \emph{purpose}, or intent, of the data, nor can any other service dictate how the data is supposed to be used---a service just takes advantage of the \emph{presence} the data. Hence, data can be reused in ways that weren't even intended when first designing the system.

Extensibility is further improved by DDS's dynamic service discovery. A newly added service can subscribe to any topic at run-time, as long as the topic's name and type are known. Similarly, a service which provides data may register new topics at will and can engage in collaboration instantaneously. At the same time, other services are entirely oblivious to the fact that a service was added. The change of topology is handled exclusively by the middleware, and minimal manual effort is needed to integrate new services.

\wnet\ also helps in building extensible systems: Software as well as hardware nodes can be easily added to existing overlays. Weave overlays are set up at host-level, \ie , each host participating in an overlay has the Weave daemon running on it. The daemon causes any container that is launched on such host to be automatically added to the overlay. There is no need for per-container configurations or scripts to be executed, which significantly eases the way software nodes may be added to the system. This process is entirely transparent, so that a container management and orchestration system does not even have to know that Weave is in place. Weave's extensibility properties also carry over to the hardware-level. If a new hardware node were to be added to the system, the only thing one would \todo{The only thing that would have to be done...?} have to do is launch the Weave software on that node, referencing the IP address of at least one other participating node. The other node would then propagate the addition of new node in the whole overlay. Shortly after, every other node in the system would know that a new node was added.

\todo[inline]{
Lastly, \docker\ brings features that greatly improve extensibility. \docker 's layered images make it possible to only exchange those parts which are in need of updates. If an application is made of a number of layers, only the.
Docker greatly facilitates fast service provisioning and deployment.

Service updates: \docker\ has versioning built-in. This makes it easier to manage several versions of the same service at the same time.
}

\paragraph{Adaptability.}
\todo[inline]{
Location transparency is given by both, \wnet , and DDS.
}

\paragraph{Testability.}
\todo[inline]{
Docker facilitates continuous integration
}



\paragraph{Interoperability.}
The approach is based on containerization as means to achieve a maximum of interoperability. In fact, interoperability is one of its main selling points. \docker\ is used as containerization technology, which allows software to run on any platform that possesses a container engine and has a kernel---properties that is not hard to come by. Additionally, in recent years, efforts to standardize and unify container technologies were launched. Driven by the \emph{Open Container Initiative} (OCI), standards aimed at providing interoperability between containerization technologies were created. Thus, there is no vendor lock-in for containerization.

Weave runs entirely within \docker\ containers. As a consequence, and unsurprisingly, it may run on any platform which is capable of running \docker\ containers. However, Weave is specifically built to work with Docker, and a great deal of modifications to the software would be needed to make it work with other technologies. Hence, an inherent dependency is present. Consequently, in order to swap \docker\ with a competing containerization tool, one would have to drop \wnet\ from the approach. Similarly, when deciding to go without any sort of containerization, Weave could not be used anymore.

Setting containerization aside, the chosen messaging middleware offers decent interoperability support. The approach suggests to define service contracts by means of topics, and in particular, their associated name, type, and QoS policies. The type is specified in a language-independent format (IDL), and is not bound to a specific technology. Thus, platform-independent service contracts are given. But interoperability support goes beyond service contracts. Contracts are of no use if services can't communicate in a platform-neutral manner. DDS provides a solution for this: its wire protocol, RTPS, ensures that applications using different DDS implementations may communicate with each other. Hence, interoperability is given---at least within the realm of DDS. 
\todo{Dependency on network stack? Which network stacks does DDS run on?}



\section{Limitations}

The benchmarks in the previous chapter demonstrated that the approach to cloud connectivity presented in this thesis is fully functional and performs reasonably well. However, the approach is far from perfect and comes with a number of limitations that need to be addressed.

Firstly, \wnet\ is not designed to be used in safety-critical systems. On their website, Weaveworks make no statement about any certification efforts that make the software suitable for the use in safety-critical scenarios. Thus, for the time being, the given approach may only find applicability for non-safety critical functions, \eg\ in the context infotainment systems. However, it may be added that \wnet\ is open source, and as such, all underlying technologies and concepts are disclosed. Thus, it is entirely plausible to implement a thoroughly verified and tested derivative of \wnet\ tailored to safety-critical systems.

In the context of vehicles, safety is inherently connected to the software system's security. Hence, proper methods are required to ensure the system's authenticity, confidentiality, integrity and privacy properties. The presented approach was not tested regarding these attributes. A rigor security analysis is needed to be able to make a well-founded statement about its aptitude.

Problem with \wnet 's encryption: password-based shared secret. How to distribute shared secret? How to renegotiate shared secret? etc.

The test on resource utilization (\cf \autoref{sec:utilization}) revealed a significant computational overhead associated with \wnet\ overlay networking. 

It may also be noted that the Docker images presented in this thesis are by no means production ready. Although there was an effort to minimize the size of the images, in real scenarios, images would be shaved down to the bare minimum, both in terms of size and capabilities. Utilities such as compilers, build tools and generally everything which is not a prerequisite to execute a given service would be removed. The images used in this thesis serve the purpose of demonstration and thus, such measures were not taken to ensure a rapid progression of this work. More time would be needed to optimize the images for production use.



\weave\ has good ideas but it is questionable whether it is the right tool for the job. It is not designed for cyber-physical systems. is not yet production ready. Unsolved problems: shared secret distribution and key renewal protocols.


The approach is by no means production ready.


Not all requirements were addressed to a satisfying degree: Safety, Testability

If not used with caution, offloading a small computation to the cloud may end up putting more load on the CPU than simply performing the computation on the on-board computer.

