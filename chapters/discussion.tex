\chapter{Discussion}\label{chapter:discussion}
In \autoref{chapter:approach}, the thesis' main approach was introduced. As part of this, an exemplary technology stack to realize the system was proposed (\cf \autoref{chapter:realization}). The exemplary solution, which is based on DDS, \docker , and \wnet , was then assessed with the aid of a number of benchmarks (\cf \autoref{chapter:evaluation}). In this chapter, the proposed solution is discussed, and its merits as well as its flaws are pointed out. The list of requirements given in \autoref{sec:requirements} and the benchmark results from the previous chapter serve as the foundation of the discussion. 


\section{Requirement Analysis}

\paragraph{Availability/Reliability.}
Moving vehicles are are very likely to lose reception during operation, \eg , when navigating through remote areas. At the center of the presented approach is cloud connectivity, and hence, the reliability of the network is a major concern. Thus, a primary objective when designing the system was to make it as resilient to connection losses as possible. A prerequisite for handling reliability issues is fast failure detection and a quick fail-over mechanism so that timing requirements can be met and downtime is kept at a minimum. With its support for redundancy and failure detection, DDS is perfectly equipped for such cases. DDS' way of guaranteeing reliable information exchange is achieved by QoS policies. For failure detection, DDS employs a liveliness mechanism whereby services are either proactively, or reactively, probed for responsiveness. If a service fails to meet the demand, it is declared ``dead''. In such cases, fallback services may be elected as (temporary) replacement. As soon as the original service's operability restored, it may take over again. Thus, DDS provides a level of reliability that allows the system to handle (intermittent) connection losses and other failures quickly.

While \wnet\ doesn't quite reach the level of replication- and failure transparency provided by DDS, it has other ways to deal with unreliable underlay networks. When a link between two nodes is interrupted \weave\ takes no proactive measures to find an alternative link but it reconnects as soon as connectivity is restored. Thus, a moderate resilience to connection loss is discernible.

\paragraph{Security.}
Security was a major concern when designing the approach. In fact, \weave 's security features were one of the primary reasons why it was chosen as overlay networking technology. In particular, its support for end-to-end encryption ensures the confidentiality and integrity of the communication channel, even in insecure networks such as the Internet. \wnet 's security is based on IPSec and state-of-the-art encryption algorithms. However, questions remain about the usability of \weave 's encryption mechanism. \weave\ employs a shared secret approach, \ie , a password needs to be present on all participating hosts. How this secret is to be securely stored and how situations of leakage are dealt with are an open question yet to be answered.

Aside from encryption, isolation is an important means to improve the security of a system. By integrating isolation measures, security perimeters can be created which are difficult to penetrate. The more layers of isolation there are the better the system can be protected from attackers. The approach leverages \docker\ to provide isolation. Each service instance is running within the perimeters of a container. However, whether \docker 's isolation properties are sufficient in terms of security is debatable \cite{xavier2013performance}. The fact of the matter is, however, that any degree of isolation is better than no isolation. Hence, for now, the security of \docker\ is considered sufficient, although a rigor security analysis is still to be done.

Another aspect that determines a system's level of security is how well it can be updated. Modern systems, and especially those building on high-level OSes, need to be supplied with security updates on a regular basis. \docker 's layered images greatly facilitate software updates as single layers may be swapped out individually. Whenever a new update is to be rolled out only the layer that changed needs to be replaced, and only that one, single layer needs to be downloaded from the server. Thus, \docker\ greatly eases the software update process.


\paragraph{Interoperability.}
The approach is based on containerization as means to achieve a maximum of interoperability. In fact, interoperability is one of its main selling points. \docker\ is used as containerization technology, which allows software to run on any platform that possesses a container engine and has a kernel---properties that is not hard to come by. \docker\ currently supports x86 and ARM. The latter is important to guarantee binary compatibility in embedded systems, which are often based on ARM architectures. Additionally, in recent years, efforts to standardize and unify container technologies were launched. Driven by the \emph{Open Container Initiative}\footnote{\url{www.opencontainers.org}} (OCI), standards aimed at providing interoperability between containerization technologies were created. Thus, interoperability, at least in terms of containerization, is not impaired.

\weave\ is, in its entirety, centered around \docker , and even the \weave\ software itself runs exclusively within \docker\ containers. As a consequence, and unsurprisingly, it may run on any platform which is capable of running \docker\ containers. Thus, hardware interoperability is given. However, due to its dependency to \docker , a lock-in situation is evident. Consequently, in order to swap \docker\ with a competing containerization tool, one would have to drop \wnet\ from the approach. Similarly, when deciding to go without any sort of containerization, \weave\ could not be used anymore.

Apart from this, the chosen messaging middleware, DDS, offers decent interoperability support. The approach suggests to define service contracts by means of topics, and in particular, the combination of their associated name, message data type, and QoS policies. The type is specified in a language-independent format (IDL), and is not bound to a specific technology. Thus, platform-independent service contracts may be realized. Beyond that, DDS also supports platform-neutral communication with its wire protocol, RTPS. RTPS ensures that applications using different DDS implementations may communicate with each other, thereby ensuring a great deal of interoperability and preventing vendor lock-in.

\paragraph{Performance.}
One of the main motivations behind the approach is to support the resource-constrained on-board computing system of vehicles by offloading computations to the cloud, and thereby improve the performance of the whole system. The benchmarks in \autoref{chapter:evaluation} demonstrate that the approach manages to fulfill the performance requirement to a satisfying degree. This is because the employed technologies were chosen, in part, on the basis of their performance properties.

DDS exhibits great performance characteristics because it is, from the ground up, designed to perform well. The fact that DDS employs multithreading-based asynchronous programming, and that virtually all DDS implementations are implemented in C++, underline this statement. In section \ref{sec:ddslatency} DDS was evaluated regarding its latency characteristics in an overlay setting. The results of the benchmark show that DDS incurs reasonable protocol overhead. In that benchmark, DDS was compared to ICMP---a protocol which is not designed for information exchange. The comparison is therefore imbalanced to the detriment of DDS. The fact that DDS still performed comparatively well is a strong argument for its aptitude. 

Similar to DDS, \docker\ was built with performance in mind. Many benchmarks have been conducted which support this statement (\eg\ \cite{adufu2015container, felter2015updated, morabito2015hypervisors, xavier2013performance}). At the same time, \docker\ is very efficient in terms of energy consumption \cite{morabito2015power}. Virtually all performance analyses agree that \docker\ incurs minimal computational and I/O overhead, provided that it is configured properly. One reason why \docker\ performs well is that programs running within containers are actual processes which run directly on the host system's kernel. Thus, no computational overhead is incurred. This is in contrast to VM-based virtualization in which programs run on an intermediate hypervisor layer which affects performance negatively. Furthermore, containers do not have to boot into an operating system, as VMs do. As a result, containers may be launched in a matter of milliseconds.

A slightly less optimistic picture paint the benchmark results for the evaluation of \wnet . The results reveal that the overlay technology adds a barely noticeable latency overhead, even when applying encryption (\cf section \ref{sec:plainlatency}). Likewise, network throughput takes only a minor hit (\cf section \ref{sec:throughput}). However, these properties only apply when enough computing resources are present. In cases where computing power is insufficient, severe network performance degradations may be the result. The reason for this is that overlay networking, \ie\ the wrapping and unwrapping of encapsulated data, puts significant load on the CPU. In section \ref{sec:utilization}, a case was explored in which the test nodes reached their computational limit such that the CPU became the bottleneck. As a result, only a fraction of the theoretically achievable network bandwidth could be utilized. Expressed in figures, the effective throughput stalled at around 23 Mbit/s. The severe computational overhead can be explained by \weave 's custom encapsulation protocol (``sleeve''), which is automatically used for overlays that span over the Internet. In this mode, packets need to traverse the \weave\ router. Because the router is a user space process, many context switches need to be performed during continuous data transmissions. This circumstance causes significant delays if many packets need to be sent in rapid succession. All in all, one can conclude that \wnet\ is definitely not the best suited technology for the use case at hand.


\paragraph{Scalability.}
\todo[inline]{FERTIG MACHEN}
Scalability has been one of the main objectives when designing the system.
system is designed to scale out: 
Services can be replicated in the cloud
new functionality can be easily added through DCPS
Docker promotes statelessness -> no shared state -> easier to scale
Beyond sheer scalability the system has the potential for great \emph{elastic} scaling

\begin{itemize}
\item anonymous multicast communication facilitates scalability. new services don't need to explicitly register to related services. All communication goes to a multicast address. The underlying infrastructure takes care that messages are distributed accordingly.
\item automatic service discovery: it's easy to add new services. It's enough to start the program and the publisher/subscriber can automatically participate in a topic.
\item Decentralization also improves scalability: In centralized systems, there is often a single point of failure which may be overloaded with increasing demand. 
\item However, performance properties when adding publishers or subscribers was not tested. Previous work?
\end{itemize}

With \docker\ it is easy to replicate services. 
\begin{itemize}
\item \docker\ can be controlled via mature RESTful API which makes it easy to launch containers in a unified manner
\item Container spin-up is extraordinarily fast. Helps elasticity.
\end{itemize}

Adding containers to a \weave\ overlay happens implicitly when the host is already running a \weave\ router. Starting the \weave\ router on a machine can be done at system start up via shell script. Gripe: It is not known if \weave 's performance degrades with many nodes in the overlay. This is future work.

(Weave nodes can be easily integrated into existing networks. When the \weave\ router is already in place on a host, merely starting a container is enough to connect it to the overlay.)

\paragraph{Extensibility.}
The extensibility of the approach is to a large extent facilitated by DDS, and in particular, the publish-subscribe paradigm. In the DCPS paradigm, data is provided ``as is'', \ie , there are no implications or restrictions \wrt\ how that data is used. A newly added service is not concerned with the original \emph{purpose}, or intent, of the data, nor can any other service dictate how the data is supposed to be used---a service just takes advantage of the \emph{presence} the data. Hence, data can be reused in ways that weren't even intended when first designing the system. By having no connotations about the data's semantics, new services can be easily added without making changes to a service's interface, or affecting other parts of the system. Extensibility is further improved by DDS's dynamic service discovery. A newly added service can subscribe to any topic at run-time, as long as the topic's name and type are known. Similarly, a service which provides data may register new topics at will and can engage in collaboration instantaneously. At the same time, other services are entirely oblivious to the fact that a service was added. The change of topology is handled exclusively by the middleware, and minimal manual effort is needed to integrate new services.

\wnet\ also helps in building extensible systems: software as well as hardware nodes can be easily added to existing overlays. \weave\ overlays are set up at host-level, \ie , each host participating in an overlay has the \weave\ daemon running on it. The daemon causes any container that is launched on such host to be automatically added to the overlay. There is no need for per-container configurations or scripts to be executed, which significantly eases the way software nodes may be added to the system. This process is entirely transparent, so that a container management and orchestration system does not even have to know that \weave\ is in place. \weave 's extensibility properties also carry over to the hardware-level. If a new hardware node were to be added to the system, the only thing one would have to do is launch the \weave\ software on that node, referencing the IP address of at least one other participating node. The other node would then propagate the addition of new node in the whole overlay. Shortly after, every other node in the system would know that a new node was added. This self-governing approach minimizes manual work, and thus, benefits extensibility greatly.

To further improve the system's run-time extensibility it must facilitate software updates. How \docker\ aids in realizing efficient software updates has already been discussed.


\paragraph{Adaptability.}
A major challenge in automotive systems is run-time adaptability. Due to their dynamic nature, vehicles are exposed to rapidly changing situations which require quick and adequate reactions. An example of a situation that needs to be handled quickly is a hardware failure. The approach utilizes DDS' failover mechanism to handle such situations. An example of this was demonstrated in section \ref{sec:failovertest}. The same principle can be applied when the vehicle is succumbed to intermittent connectivity: when the vehicle loses reception while using a cloud-based service, the system can quickly switch to a vehicle-based service. Potential for more advanced ways to deal with operational situations is provided by \docker . The \docker\ daemon exposes an API by which containers can be started and destroyed remotely. One could think of a central management and orchestration component which monitors the state of the system and, with help of the API, can start and stop services, depending on situational demand. 

Other aspects of adaptability are the ability to react to changes in requirements by means of software updates, and adaptability in terms of platform independence. Both aspects have already been discussed.


\paragraph{Testability.}
With the help of containers, software can be made portable so that it can run on a variety of platforms. This principle is taken advantage of by CI/CD platforms. CI/CD pipelines, in general, perform the following steps: first, the application's program code is downloaded from its source code repository to dedicated CI servers whenever changes are committed to the repository. Then, the software is built and all automated tests are run. In this step, containers are often used  \cite{barna2017delivering} to guarantee the processes' determinism: building and testing the software within containers ensures that all dependencies are available and that the result of successive builds is always the same. Consequently, the built program runs on the developer's workstation, the CI server, and the production server in the exact same way.
When one of the tests fail, the development team is notified instantaneously so that they can fix the error as soon as possible. If all tests pass, the software is automatically deployed to the production environment. This process ensures rapid development velocity, and more importantly, helps to verify the correctness of the software during the whole development cycle. This principle was demonstrated in section \ref{sec:multiplat}, were a minimal CI/CD pipeline was described. Although the presented pipeline did not include an automated testing step, such step could be easily integrated. 

%
%
%
%
%
%
%
%
%
%
\section{Limitations}
The benchmarks in the previous chapter demonstrated that the approach to cloud connectivity presented in this thesis is fully functional and performs reasonably well. However, the prototypical implementation is far from perfect and comes with a number of limitations that need to be addressed.

As the presented implementation is merely a proof of concept, several aspects were insufficiently evaluated. First and foremost, little attention has been paid to the safety requirements of vehicles. \wnet\ is not designed to be used in safety-critical systems. On their website, Weaveworks make no statement about any certification efforts that make the software suitable for the use in safety-critical scenarios. Thus, for the time being, the presented approach may only find applicability for non-safety critical functions, \eg\ in the context infotainment systems. However, it may be added that \wnet\ is open source, and as such, all underlying technologies and concepts are disclosed. Thus, it is entirely possible to implement a thoroughly verified and tested derivative of \wnet\ tailored to safety-critical systems.
The same is true for \docker . \docker\ just so happens to be the most mature containerization technology, which is why it was chosen for the prototype. However, \docker\ is by no means suitable for safety-critical systems. But like \wnet\ , the concepts that underly \docker\ are based on well-known technologies and it is entirely transparent how \docker\ works under the hood. Furthermore, it may be noted that the \docker\ images presented in this thesis are not meant to be used in production. Although there was an effort to minimize the size of the images, in real scenarios, images would be shaved down to the bare minimum, both in terms of size and capabilities. Utilities such as compilers, build tools and generally everything which is not a prerequisite to execute a given service would be removed. The images used in this thesis serve the purpose of demonstration and thus, such measures were not taken to ensure a rapid progression of this work. More time would be needed to optimize the images for production use. Additionally, more measures are required to improve the containers' isolation. For example, the number of system calls that a containerized process can invoke should be reduced significantly through tools like \emph{SELinux}.

Another limitation related to the used technologies is that they are not universally usable on all hardware platforms. For example, \docker\ requires the substrate system to run a Linux kernel and a container runtime. This requirement is hard to fulfill in many cases, \eg , for the use with smart phones. This circumstance further restricts the system's potential use cases.

An additional aspect which was negligently evaluated is security. Although \linebreak\wnet\ promises to provide end-to-end encryption, it is unknown how effective and robust the employed encryption scheme is. A rigor security analysis is needed to be able to make a well-founded statement about this aspect. Furthermore, questions about the encryption mechanism's usability remain unanswered. To encrypt a \weave\ overlay, all hardware nodes need to be supplied a shared secret. The question how this secret shall be distributed and stored securely was not answered in this thesis. 
Another major caveat concerning \weave 's usability is its extensive resource utilization.  When overlays span over long distances, \weave\ employs a custom encapsulation protocol which is applied by a user space process. Thus, a context switch is needed for every packet that is sent, making this process highly inefficient. This circumstance was demonstrated in section \ref{sec:utilization}, where the effect of overlay networking on CPU utilization was investigated. The results of this experiment show that \weave\ overlays may introduce CPU-bound bottlenecks for high-throughput applications. As energy efficiency is one of the main motivating factors behind the devised system, one can conclude that \wnet\ is unsuitable in automotive use cases.

Overall, the provided implementation is not, in any way, suitable for production use in vehicular environments. This, however, was never the goal of this thesis. \wnet\ and \docker\ were both chosen for the lack of better alternatives. Furthermore, both tools provide easy-to-use interfaces which allowed for quick prototyping, ensuring the rapid progression of this thesis. 

