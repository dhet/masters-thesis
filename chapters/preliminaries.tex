

\chapter{Preliminaries}\label{chapter:preliminaries}

\section{Cyber-Physical Systems}

\begin{itemize}
\item characterized by limited resources
\item often real-time systems
\item often safety critical
\item Sensors and actors connected to ECUs
\item Examples of a cyber-physical system are vehicles
\item x-by-wire
\end{itemize}


\paragraph{Automotive System Engineering}
Control systems in modern vehicles are typically implemented as a collection of dozens, if not hundreds, of Electronic Control Units (ECUs) dispersed within a vehicle. Originally, there was no conscious decision to design automotive systems that way. Much rather, it is the result of an evolutionary process. At first, individual ECUs, each dedicated to a single purpose, were implemented in vehicles. At this point, ECUs were isolated from each other and no sense of cohesion was present in the system. This changed with the introduction of advanced wiring and bus systems that allowed ECUs to interact with sensors and actors. It was then only a matter of time until the bus systems were used to furthermore interconnect ECUs, which could then be used in interplay to create new, innovative functions \cite{broy2006challenges}. However random this evolution might have been, there are several benefits to the dispersed approach (as opposed to a centralized one). By having ECUs close to the sensors and actors they control, wiring effort is kept low, which results in low transmission latencies. 

Problems according to \citeauthor*{broy2006challenges}:
\begin{itemize}
\item Often highly proprietary
\item Limited re usability of software: 90\% of software is re-written 
\item Lack of tools and automation
\end{itemize}


Industry profile according to \citeauthor*{broy2006challenges}:
\begin{itemize}
\item Highly modular: several teams working independently on different technologies
\item Much is outsourced: many technologies are developed by suppliers, rather than the OEM 
\item Development: Many systems must interact -> vehicles evolve from an assembled device to an integrated system
\item Behavior becomes programmable: from comfort functions to steering and breaking: everything can be controlled by software.
\item moving away from specialized ECUs to general-purpose commodity systems
\end{itemize}

%
%
%
%
%
%
%
%
%
%

\section{Distributed Systems}
Modern vehicular E/E-Architectures\footnote{Electric/Electronic} are comprised of a large number of distributed, connected sensors, actors and control units, and hence, fall into the category of \emph{distributed systems}. The term "distributed system" entails many things and just as many definitions of the term exist. A definition that most would agree upon is the one given by \citeauthor*{tanenbaum2017distributed} \cite{tanenbaum2017distributed}: 
\begin{quote}
"A distributed system is a collection of autonomous computing elements that appears to its users as a single coherent system."
\end{quote}

The first aspect to consider in this definition is the word \emph{collection}. Distributed systems are made up of a number of \emph{nodes} which may occur in the form of either hardware devices, or software processes. Nodes work together to achieve a common goal. For this, they need to exchange messages (\cf \autoref{sec:middlewares}). Furthermore, the definition names \emph{autonomy} as a characteristic of distributed systems. Nodes, on their own, are autonomously acting entities, with their own, individual sets of rules and behavior. At the same time the system needs to be kept together. \emph{Groups}, which individual nodes may join, are a tool to achieve this. There are open groups, which every node may join, and closed groups, which employ an authorization mechanism to control access. 
Groups aim to provide \emph{coherence}, which is another aspect of the definition given above. By that definition, however, the coherence of the system is only \emph{perceived}. \Ie , to users, whether they are humans or programs, a distributed system presents itself as a single entity, even though it is in actuality comprised of a number of physically dispersed processes and resources. This principle is called \emph{distribution transparency}. \citeauthor*{tanenbaum2017distributed} \cite{tanenbaum2017distributed} separate this principle into several aspects. The first one to note is \textbf{location transparency}. At the root of location transparency is the desire to hide the physical location of resources. A common method to achieve this is by giving resources names. A user who wants to access a resource can thus refer to it by name, \eg\ a URL, while remaining oblivious of its actual location. Under the hood, communication is still based on location-dependent addresses, but such details can be hidden by a name resolution service. Naming furthermore facilitates another kind of distribution transparency: \textbf{Relocation transparency}. As the name suggests, relocation transparency aims to hide the fact that resources may move without the user taking notice. In the example of the aforementioned name resolution service, this can be achieved by reconfiguring the service to redirect users to a location different than the one previously known. To the user, still, the resource appears to be in the same location as it only knows its name. Related to relocation transparency is \textbf{migration transparency}, but in contrast to the former, migration transparency refers to the mobility of the \emph{user}. A migration transparent system allows a user to roam freely, while maintaining connectivity to the rest of the system. Examples of such systems are cellular networks.

Another aspect of distribution transparency is \textbf{replication transparency}. Distributed systems often provide means to replicate nodes or resources, \eg\ to improve scalability. Replication transparency states that all such replicas appear as one to the user. In addition to scalability, replication can be helpful to provide failure resilience. If a given node fails, and a replica is available, the user can be automatically redirected to the replica. This is also known as \textbf{failure transparency}.

The last kind of distribution transparency that \citeauthor*{tanenbaum2017distributed} list is \textbf{access transparency}. Access transparency refers to how data is presented to different users. Several users may have entirely different views of the same data\todo{explain better}. At the basis of this is a basic principle of software engineering: the separation of data and its representation.

%
%
%
%
%
%
%
%
%
%

\section{Middlewares} \label{sec:middlewares}
A prerequisite for the coherence property of distributed systems is the need for nodes to engage in collaboration. More precisely, distributed applications need a way to pass messages, or data, between different threads of execution. For this purpose, \emph{middlewares} \cite{bernstein1996middleware} are commonly used. Although message passing is a prime example of a middleware's use case, there are many other important concepts for which middlewares exist, \eg , transaction management in database systems. The primary goal of middlewares is to abstract away such concepts so that programmers can focus on implementing business logic and shipping features, instead of having to deal with the underlying specifics. Middlewares are implemented as a software layer that sits between operating system and the actual applications. They are often included in the form of libraries that make the middleware's functionality available to the programmers by means of an Application Programming Interface (API). 

The need for middlewares becomes particularly evident in the example of \emph{messaging}. Messages need to be sent over a physical mediums which are often, by nature, unreliable. To ensure reliability, many things need to be taken care of, \eg , error detection, repetition mechanisms, etc. In addition, guarantees must be given that messages are delivered to the right receivers. Therefore, addressing and routing mechanisms must be in place. These are just a few examples of hard-to-solve problems related to messaging. Managing these things manually, and implementing according measures from the ground up is hardly feasible for programmers. Messaging middlewares are a good way to streamline this process. An exemplary messaging middleware may be included in a software project in the form of a library which exposes an API. In the following, all the programmer needs to do to send messages is to invoke a simple function, \eg , \texttt{middleware.sendBroadcast("Hello, World!")}. The middleware then ensures that the message is delivered to the right recipients over whichever transport is available. To receive messages, the programmer may, in the case of this exemplary middleware, define a callback function which the middleware calls automatically whenever a new message is available. The callback function could have the form \texttt{void receive(string message, string sender) \{ /*...*/ \}}.

%
%
%
%
%
%
%
%
%
%

\section{Networking}

\subsection{Overlay Networks}
Distributed systems are often organized as \emph{overlay networks}\footnote{The term "overlay networks" is often used interchangeably with its abbreviated form, "overlays"} \cite{tarkoma2010overlay}. An overlay network is a logical network which connects nodes, or peers, in an abstract, high-level manner. Naturally, in order to enable information exchange between the peers, overlay networks require a substrate physical network (\emph{underlay}) over which data can be transmitted. As opposed to physical networks, which connect \emph{physical machines}, overlay networks connect \emph{processes}. An important thing to note is that overlay networks are entirely decoupled from the physical infrastructure, such that both networks may evolve (change topology) independently without affecting their operability \cite{tanenbaum2017distributed}. For example, an added node in an overlay network does not necessarily entail the addition of a physical node. Conversely, the removal of a physical node does not necessarily result in connection loss of a logical node. An example of this is the Internet \cite{vaezi2017virtualization}, which spans a worldwide network of nodes that is resilient to failures, such that, when a physical node breaks, a redundant path to the target node may be taken. Other examples of overlay networks are VPNs, Peer-to-peer (P2P) networks and voice over IP (VoIP).

There are two types of overlay networks: \emph{structured} and \emph{unstructured} overlay networks. In the former, peers are organized in a specific, deterministic manner, such that each node has its firm place and an immutable set of neighbors. Unstructured overlay networks, on the other hand, allow the topology to change dynamically. In order for this to work, each node maintains an ad-hoc list of neighbors that is to be updated continuously \cite{tanenbaum2017distributed}. In the context of this thesis, unstructured overlay networks are of particular interest due to the dynamic nature and the reliability characteristics of mobile systems. 

Different ways exist to create overlays. The one this thesis is concerned with is the \emph{Ethernet virtualization}-type of overlays, which are created by using IETF VXLAN\footnote{"Virtual eXtensible Local Area Network"}. 


Ethernet virtualization: VLAN tags to separate traffic and to build L2/L3 overlays.


\subsection{Multicast}
The simplest form of communication is one-to-one communication, which is also referred to as \emph{unicast}. In unicast, every node has an address by which it can be contacted. In most cases, unicast is sufficient for data exchange. However, in distributed systems, information frequently needs to be propagated to multiple receivers simultaneously. Unsurprisingly, this type of communication is called \emph{multicast} communication. 

benefits: No hard-coded addresses

Multicast can be implemented on both, network and application-level.

Support for multicast in WANs is rather limited.

%
%
%
%
%
%
%
%
%
%

\section{Cloud Computing}

The idea of cloud computing is to provide access to remote computing resources  (\eg , networks, servers, storage, applications, and services) in a convenient, on-demand manner \cite{mell2011nist}. Customers of cloud providers can rent these resources to use them at their will. By outsourcing their IT infrastructure into the cloud, companies can significantly reduce capital and operational expenditures (CAPEX/OPEX) that are typically associated with running an on-premise infrastructure.\todo{citation} Other benefits include easier maintenance and accelerated time-to-market times. Several pricing models for cloud services exist. Customers often have the choice between a set monthly fee, or they may take advantage of a pay-per-use model, whereby providers bill their users, \eg , on the basis of CPU time.

Cloud infrastructures are typically implemented as multi-tenancy systems in which the same hardware is shared among many customers ("resource pooling"). An enabling technology for this is virtualization. Each customer is assigned one or more virtual machines (VMs) running on one or more physical servers. For its users, the alloted computing environment appears as a single, isolated physical machine. The amount of disposable resources can be controlled for each VM individually, allowing for fine-grained resource tuning according to demand.

A major selling point of cloud computing is scalability. Many cloud providers allow for the dynamic allocation of resources depending on demand. To customers, the available resources appear as if they were unlimited when in actuality the substrate resources are alloted and released under the hood in an elastic manner. To steer this behavior, \emph{elasticity controllers} can be employed which allow customers to define rules to control when and how scaling measures are performed. \Eg , when a CPU utilization threshold is reached, the system can be instructed to automatically launch an application replica. Subsequently, a load balancer can be used to distribute the load between the instances \cite{vaquero2011dynamically}.


\paragraph{}
Cloud computing presents itself in the form of several usage models. The most notable ones are: \emph{Infrastructure as a Service} (IaaS),  \emph{Platform as a Service} (PaaS),  and \emph{Software as a Service} (SaaS) \cite{mell2011nist}.

\begin{description}
\item[IaaS] In the IaaS model, sheer, usually virtualized, hardware is provided, on which customers can install and run arbitrary software. Customers have only basic control over their virtual infrastructure's hardware composition, but may take influence on the operating system level.
\item[PaaS] The PaaS model presents a higher level view on the infrastructure. In this model, customers don't have full control over their VM instance. Instead, they can deploy their software in predefined application-hosting environments \cite{mell2011nist} which are typically centered around a certain technology, \eg\ .NET, or node.js, etc. Examples for this type of services are Microsoft Azure or Google App Engine.
\item[SaaS] Finally, the SaaS model is the highest level of cloud services.\todo{sounds weird} SaaS typically describes applications which are hosted on cloud platforms. These applications are usually accessible by means of thin clients, most notably web browsers. Customers have the least control over the cloud service and can only take influence via application-level configurations \cite{mell2011nist}. Examples of SaaS applications are browser-based e-mail services or video streaming platforms.
\end{description}


\section{Real-time Systems}

\section{Safety-critical Systems}
A system is considered emph{failed} when it cannot meet its promises. [Tanenbaum, S 426]

An \emph{error} may lead to system failure.

A \emph{fault} is the cause of an error. Faults can be caused by bugs in the software or unforeseeable circumstances. Some faults are avoidable and some are out of the control of the system developers. Nevertheless, all faults need to be dealt with.

A \emph{transient fault} is one that affects the system temporarily and can be circumvented by repeating the same operation.

An \emph{intermittent fault} occurs on and off, seemingly out of nowhere, without being reproducible .

A \emph{permanent fault} is one that persists until the root of the fault is found and repaired.

\emph{Fault tolerance} is a systems ability to continue operation, even in the presence of faults.

Failure masking by redundancy: three types: information r. (hamming code), time r. (repeat error), physical r. (redundant processes or hardware)


\input{chapters/sections/docker}


\input{chapters/sections/dds}