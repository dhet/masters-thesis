\chapter{Conclusion}\label{chapter:conclusion}
To conclude this thesis, a summary is first given in which the context, problem statement, and the chosen approach is recapitulated. Then, ideas for future research opportunities are provided.

\section{Summary}\label{sec:summary}
\subsection{Context}
Current trends in the field of automotive mobility, such as autonomous driving, are the cause of an increased demand for computational power and the need for advanced data collection techniques. Associated with this development is an inherent increase in energy consumption. However, an objective should be to keep the energy usage of vehicles' electronic systems as low as possible. This applies especially in the wake of the ever-increasing importance of electro mobility where every bit of energy is needed to fuel the vehicle. In the face of this dilemma traditional vehicular on-board technologies are reaching their limits, and thus, new ways to tackle tomorrow's mobility challenges need to be investigated. One possibility to overcome the constraints imposed by the limited capabilities of current vehicles' computing infrastructure is offered by \emph{cloud computing}. Cloud computing has been around for many years now and many modern businesses thrive on the innovation opportunities that this technology facilitates. However, comparatively little attention has been paid to the prospect of integrating them into the automotive domain. A reason for this might be the special requirements that apply to this particular industry. The most prominent challenge is the mobility aspect of vehicles which makes it difficult to maintain a reliable communication channel to the outside world. This issue will be greatly alleviated with the upcoming 5G cellular network that is currently being rolled out. Supported by such technologies, cloud computing paves the way for new, innovative functions for tomorrow's vehicles. For example, computationally intensive tasks could be offloaded to high-performance computing systems with the aim of relieving the vehicle's constrained on-board system, and to boost the system's performance. Further potential lies in the simplified collection of telemetry data for real-time health monitoring and remote troubleshooting as well as in the provisioning of backup services for safety-critical functions.

\subsection{Approach}
This thesis was created as a response to the situation \todo{respond to situation?} laid out in the previous section. The goal of this work was to present a system that connects vehicles to clouds as means to facilitate innovative applications. For this, an approach was chosen that lends many concepts from classic bus systems in which dispersed components communicate with each other anonymously by reading and writing messages to a shared, logical medium. The characteristic that makes the approach special is that the medium is virtually extended into the cloud with the help of network virtualization. As a result of this, everything that is put onto the bus can be read from within the cloud. Similarly, applications in the cloud can push data onto the bus, which can then be consumed by the vehicle's on-board system. The approach employs anonymous communication in order to provide location transparency: in the eyes of the vehicle it does not matter whether a given data sample originated in the vehicle or anywhere else. This greatly facilitates the offloading of vehicular functionality into the cloud. The approach builds on a service-oriented architectural paradigm in which the vehicle's functionality is split into a discrete number of \emph{services}. Each service fulfills a purpose which, in traditional E/E architectures, would correspond to an ECU's functionality.

Three key challenges were identified that need to be tackled in order to realize such system. Firstly, reliable, anonymous information exchange needs to be facilitated such that individual services are able to communicate in a reliable manner, without the need for explicit references to one another. For this purpose, DDS was proposed. DDS, being a messaging middleware standard designed for mission- and business critical systems with high reliability and real-time requirements, is a perfect match for the automotive use case.
%is an open messaging middleware standard for distributed applications. The standard is designed for mission- and business critical systems with real-time requirements. As such, it is a perfect match for the automotive use case. 
The foundation of these properties is laid by \emph{QoS policies}, which serve to control the level of reliability and to establish interface contracts between services. For data dissemination, DDS employs the data-centric publish-subscribe communication paradigm by which data is made available through \emph{topics}. Contrary to RPC-style communication, in which data exchange is based on \emph{instructions}, DDS places \emph{data} at center-stage. Any service that wishes to expose a certain kind of data may \emph{publish} respective data samples on a topic associated with that data. Conversely, any service that is interested in the reception of that sort of data may \emph{subscribe} to that topic. Communication takes place entirely anonymously, \ie, services do not know their peers, and consequently, can not address each other directly. The subsequent dissemination of data is then performed by the DDS middleware "under the hood". This approach to information exchange greatly facilitates scalability and extensibility.

In order to enable services to run on both, the vehicle and the cloud, they need to be portable, which poses the second challenge to be tackled: isolation. The approach intends services to be packed into self-contained execution environments with all their dependencies. This would allow them to run independently from each other, on a variety of platforms. To achieve this, the use of containerization technology, and in particular, \docker , is proposed. Containers provide OS-level isolation through kernel namespaces. Namespaces wrap a set of system resources and present them to the container process as if they were dedicated to it. Each aspect of a container runs in its own namespace and its access is limited to that namespace. Similarly, containers have by default no access to the host's filesystem. Instead, they come with their own "cutout" of a filesystem which is specified in each container's respective image. In that image, all of a containerized application's dependencies and its runtime are contained. Containers thus provide portability across a multitude of operating systems. The only prerequisite is that the host OS runs on a kernel and provides a container runtime. What makes containers especially appealing for the intended use case is that they exhibit excellent performance attributes, that they may be launched in a matter of milliseconds, and that they may be controlled via HTTP API. The latter characteristic makes it possible to programmatically launch and tear down individual containers in a uniform manner, establishing the basis for orchestration tools and elasticity controllers.

The last remaining challenge to realize the system is to connect the dispersed services with each other in a location transparent manner. As means to achieve this, SDN-assisted overlay networks were suggested. To demonstrate the general feasibility of the approach, \wnet\ was selected for this purpose. \wnet\ is a tool which aims to enable advanced overlay networking capabilities for \docker\ containers which are dispersed throughout different cloud environments. \docker\ itself comes with overlay networking out of the box, however, those do not support support encryption and multicast, which is a crucial requirement for the intended use case. \weave\ is implemented as a daemon that runs on all hosts that participate in the overlay. Whenever a container is launched on such host, the daemon automatically adds the container to the overlay. Changes in the topology are constantly propagated to other containers via spanning tree-based broadcast and a gossiping protocol. Weave effectively creates a self-governing service mesh in which nodes communicate through VXLAN tunnels. In this mesh, containers may communicate freely with each other across physical boundaries. From the viewpoint of a container it does not matter whether a communication partner is located on the same host or on a remote server in a data center. 

\paragraph{}
The three technologies described above (DDS, \docker , and \wnet ) were combined in a novel way to realize an exemplary implementation of the envisaged system. Selected aspects of this setup were evaluated in \autoref{chapter:evaluation}. In that chapter, a number of benchmarks were presented which serve to demonstrate the approaches' general feasibility and to evaluate its performance attributes and fail-over characteristics. The results of the benchmarks prove that the approach, in itself, performs extraordinarily well. Network latency as well as throughput take only a minor hit in \weave -enabled overlays. Similarly, DDS adds a moderate, but justifiable, overhead. However, severe deficiencies were discovered in \weave 's overlay implementation as it puts a unnecessarily high load on CPUs. The (admittedly feeble) test nodes hit a CPU-bound wall quite early in the throughput benchmark, effectively prohibiting high-volume data transmissions. Especially in consideration of the goal to reduce energy consumption, this insight leads to believe that \wnet\ is not the right tool for the job. Nevertheless, the general feasibility of using VXLAN-based overlays as means to connect widely dispersed components was demonstrated successfully.
\todo[inline]{failover test}


\section{Future Work}
Although considerable effort was made to quantify the quality attributes of the approach, it is far from being fully evaluated. Future research could investigate many questions which were left unanswered in this thesis. Especially \wnet , which is a technology rooted in the software industry, and has no bonds to the scientific domain, would greatly benefit from further research efforts. Questions of interest would be, for example: To which extent can \wnet\ scale to a greater number of nodes, and does it suffer from performance degradations with an increase in participating entities? How fast can \wnet\ adapt to changes in the underlay's topology? Can it deal with nodes getting assigned new IP addresses? It was furthermore stated that nodes in a \wnet\ overlay automatically reconnect when they lose connection to the other nodes---how fast can the reconnection be accomplished? To which degree does \weave 's sleeve mode impact performance, compared to fast datapath mode? Can \weave\ be used in elastically scaling PaaS systems or Amazon's EC2? Apart from all that, how does \weave\ compare to other, competing technologies, such as \emph{flannel}\footnote{\url{www.github.com/coreos/flannel}} and \docker 's native overlays?

These questions assume that it is worth pursuing \wnet\ as overlay networking technology. This, however, in itself is an unanswered question. Because, as it stands, \wnet\ is the major weak point of the approach. While it is still the only viable solution available, as it supports encryption and IP multicast, many deficiencies relevant to the automotive use case are evident. However, the underlying principles are well known and well understood, and the general feasibility of the these principles was successfully demonstrated in this work. Thus, there are no technical barriers to realizing a system based on the underlying concepts which is better suited for the automotive use case. 

\todo{Ã¼bergang} A weak point in the testing methodology which pervades throughout all benchmarks in \autoref{chapter:evaluation} is that the tests were performed under laboratory conditions. The setup was connected to the cloud by means of a stable broadband Internet connection. These conditions obviously don't apply to real life scenarios. Thus, further testing in such scenarios would be required to make a grounded assessment of the approaches' real-world applicability. Optimally, the system would be integrated into a real, moving vehicle with 5G-enabled Internet access. In this context, it would also be interesting to see to which extent the approach would benefit from 5G's rich set of innovative features, such as \emph{network slicing}---a novel way to facilitate advanced network scaling techniques. By means of slicing, the network is separated into a number isolated slices which are then used by different applications. Each slice is highly specific to its application's use case and can enforce corresponding QoS requirements\todo{citation}. Intuitively, the approach, and especially systems based on DDS, would benefit greatly from this.

Further research potential lies in the continuative exploration of farther-reaching use cases. This work investigated only a small subset of possible applications facilitated by publish-subscribe communication in overlay networks. A major strength of the approach lies in its ubiquity, \ie\ it is meant to be applied in systems consisting of many interconnected entities. So far, however, only the "vehicular cloud" use case was investigated. While a vehicle, with all its contained ECUs, is in itself a distributed system, only dozens of components are connected. It would be interesting to see the approach being used in other use cases in which not dozens, but thousands, of entities are present, \eg\ in the context of sensor networks and other (industrial) IoT applications. Another possible use case would be an V2X scenario in which not a single vehicle is connected to the cloud, but also vehicles among each other.

\todo[inline]{
Rolling updates via Docker?
}


\todo[inline]{
Maybe in the future: system inspired by network function chaining, where load is dynamically distributed on different nodes depending on a number of factors, \eg , current load, computational power, etc. Optimization problem.
}

\todo[inline]{
The presented approach does not consider that certain functionalities have different hardware requirements, \ie , a service requiring camera footage needs to be deployed on a node that has a camera attached to it. The approach does not yet accommodate this. Container orchestration systems such as kubernetes or \docker\ Swarm offer a solution to this problem. Such systems may control compatibilities through \emph{tags} that may be attached to containers and nodes alike. Only if a node and a container have matching tags then the container may be deployed on that node. In the example, a tag like "front-camera" could be used to indicate that a service may only be deployed on a node with an attached camera. A container orchestration system could be easily integrated into the presented approach. 
}


